# IDC Project

This document will describe the design, structure, and technologies used to implement the Internal Dependency Checker (IDC) across three main stages: creation of state files, generation of reports, and data visualization.

## Technology and tools

|              I. Stage               |                 II. Stage                                       |     III. Stage   |
|-------------------------------------|-----------------------------------------------------------------|-------------------|
| NodeJs (v18)                        | Docker                                                          | CSS, HTML, JavaScript and chart.js |
| TypeScript and Jest                 | Bash                                                            | Elasticsearch |
| Makefile and make                   | JavaScript and NodeJS                                           | Kibana        |
| NVM                                 | Makefile and make                                               | AWS services â€¦ |
| GitHub REST API and set GITHUB_KEY  | OWASP dependency tool and other dependency logic <br> (Java, Node, Python  Ruby, Terraform and others) | DevOps configs and others  |

## Structure

|  Directory  |                                                                 |
|-------------|-----------------------------------------------------------------|
| `test`   | Contains jest tests for the NodeJS scripts.                            |
| `src`    | Contains NodeJS files like `cli.ts`, `main.ts`, `clone.ts` and `state.ts`, these will be transpiled in the `dist/` folder |
| `infrastructure/` | Contains the compose file, and other folders, which serves as the bootstrap for all the services. |
| `infrastructure/dashboard/` | contains files and configurations for running Git scripts on an alpine image and deploying a Nginx web application on a related image using Docker Compose. The application will run on `localhost:8080`.. |
| `infrastructure/repos/` | Contains all repositories per organisation. |
| `infrastructure/utils/` | Contains bash utility files shared between containers. |
| `infrastructure/output/` | Output logs are stored in this folder whenever the command `make docker-up`  (`infrastructure/docker-compose.yml up &> $(DOCKER_COMPOSE_OUT_FILE_NAME)`) is executed. The log file follows a naming convention such as `repos__docker__compose__output__2023-06-23_12-07-05.txt` |
| `infrastructure/reports/` | JSON audit reports per language and technology are generated by the script during runtime and saved in this folder. |
| `infrastructure/dependencies/` | Docker files and related script files for each configured dependency language (csharp, go, java, kotlin, node, perl, php, python, ruby, ...). |
| `infrastructure/vulnerabilities/` | Docker files and related script files for each configured vulnerability check (docker, gitleaks, terraform, ...). |

## Stages

### I Stage

Creation of the state files through `nodejs` scripts

Repos info file, `repos_info.json`

```txt
{
    "repos": {
        "list": [ ... ],
        "details": {
            {
                "full_name": "cabinetoffice/internal-dependency-checker",
                "visibility": "public",
                "html_url": "https://github.com/cabinetoffice/internal-dependency-checker",
                "url": "https://api.github.com/repos/cabinetoffice/internal-dependency-checker",
                "description": "",
                "created_at": "2014-02-13T17:16:03Z",
                "archived": false,
                "members": [],
                "teams": []
            }
            ...
        }
    },
    "members": {
        "list": [ ... ],
        "details": {
            ...
        }
    },
    "teams": {
        "list": [ ... ],
        "details": {
            ...
        }
    }
}
```

Repos list file, `repos_list.json`

```txt
{
    "repos": {
        "repos__cabinetoffice__repo1": {
            "repo_path": "repos/cabinetoffice/repo1",
            "file_name": "repos__cabinetoffice__repo1"
        },
        "repos__cabinetoffice__repo2": {
            "repo_path": "repos/cabinetoffice/repo2",
            "file_name": "repos__cabinetoffice__repo2"
        },
        "repos__cabinetoffice__repo3": {
            "repo_path": "repos/cabinetoffice/repo3",
            "file_name": "repos__cabinetoffice__repo3"
        }
    }
}
```

State file, `state.json`

```txt
{
    "python": {
       ...
       {
         "repo_path": "repos/cabinetoffice/repo",
         "file_name": "repos__cabinetoffice__repo__dir1__dir2",
         "repo_file_path": "repos/cabinetoffice/repo/dir1/dir2/",
         "file1": "repos/cabinetoffice/repo/dir1/dir2/requirements.txt"
        }
    },
    "node": {...},
    "terraform": {...},
    "ruby": {...},
    "php": {...},
    "java": {...},
    "docker": {...},
    "kotlin": {...},
    "go": {...},
    "perl": {...}
    ...
}

```

### II Stage

Running containers will perform audits and checks for vulnerabilities and security issues, for each project, which will then be saved in a related folder within the (`infrastructure/report` directory).

- Docker is the natural choice to ensure consistent execution across various languages and technologies, mitigating the risk of compromising the local machine when installing dependencies and libraries. Additionally, using Docker makes it easier to create images based on specific platform or technology versions.

- We are using the compose file `infrastructure/docker-compose.yml` to build and run all containers with
`docker compose -f infrastructure/docker-compose.yml build` and `docker compose -f infrastructure/docker-compose.yml up &> $(DOCKER_COMPOSE_OUT_FILE_NAME)`, check Makefile for details.

- Each service will have access to three shared volumes. The first volume will contain JSON audit reports per language and technology `/reports`, the second volume will contain a repository folder per organisation `/repos`, and the third volume will contain a folder with Bash utility files `/utils`.

- After building and running the images, each scripts will fetch information from the state file and iterate over the related, generating checks reports.

### III Stage

To analyse and gain insights from the JSON audit and other checks files Elasticsearch and Kibana services will be used. This tool, ensure comprehensive analysis and filtering of dependencies and vulnerabilities across all the organization's repositories. This will provide us with valuable insights and enable effective monitoring and management of our codebase.

Furthermore we have created a simple IDC dashboard used to visualize GitHub repository details.

Documentation and code overview per each language and technology can be found in the `/docs` directory.
